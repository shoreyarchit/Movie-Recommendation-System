{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Movie Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - 1 -Computing Target (Xij) dataset from movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading Datasets\n",
    "\n",
    "ratings_ds = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "movies_ds = pd.read_csv('ml-latest-small/movies.csv')\n",
    "tags_ds = pd.read_csv('ml-latest-small/tags.csv')\n",
    "links_ds=  pd.read_csv('ml-latest-small/links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding column to ratings table to check whether user likes a movie or not\n",
    "\n",
    "ratings_ds['Like']=np.where(ratings_ds['rating']>=4,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_ds2 = ratings_ds.drop(['rating'],axis=1) #Dropping rating column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a pivot using userId and movieId of ratings table\n",
    "\n",
    "ratings_ds2_pivot = ratings_ds2.pivot(index = 'userId', columns ='movieId', values = 'Like').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 9724)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_ds2_pivot.shape#matrix created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a co-occurence matrix , Each entry Xi,j is the number of users who like both movie i and j\n",
    "rating_co_occ = ratings_ds2_pivot.T.dot(ratings_ds2_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "movieId                                                                   \n",
       "1         147.0    21.0    11.0     0.0     7.0    27.0     7.0     1.0   \n",
       "2          21.0    50.0     5.0     0.0     4.0     8.0     6.0     0.0   \n",
       "3          11.0     5.0    18.0     0.0     4.0     4.0     5.0     1.0   \n",
       "4           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5           7.0     4.0     4.0     0.0    12.0     3.0     4.0     1.0   \n",
       "\n",
       "movieId  9       10       ...    193565  193567  193571  193573  193579  \\\n",
       "movieId                   ...                                             \n",
       "1           4.0    19.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "2           0.0     9.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "3           2.0     3.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "4           0.0     0.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "5           1.0     2.0   ...       0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  193581  193583  193585  193587  193609  \n",
       "movieId                                          \n",
       "1           0.0     0.0     0.0     0.0     0.0  \n",
       "2           0.0     0.0     0.0     0.0     0.0  \n",
       "3           0.0     0.0     0.0     0.0     0.0  \n",
       "4           0.0     0.0     0.0     0.0     0.0  \n",
       "5           0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 9724 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_co_occ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 9724)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_co_occ.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creating and optimising the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting rating_co_occ to matrix with diagonal elements as 0 to help in loss function\n",
    "\n",
    "observed=rating_co_occ.as_matrix()\n",
    "np.fill_diagonal(observed, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., 21., 11.,  ...,  0.,  0.,  0.],\n",
       "        [21.,  0.,  5.,  ...,  0.,  0.,  0.],\n",
       "        [11.,  5.,  0.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting matrix to tensor using torch\n",
    "\n",
    "observed = torch.from_numpy(rating_co_occ.as_matrix()).float()\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a reference table with movieId, indexes of movies, movie name and genre\n",
    "\n",
    "reference = rating_co_occ.reset_index()\n",
    "reference = reference.merge(movies_ds, on='movieId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reference[\"movie\"]=reference[\"title\"].str.split('(',expand=True)[0].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>grumpier old men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 9728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId     1     2     3    4    5     6    7    8    9        ...         \\\n",
       "0        1   0.0  21.0  11.0  0.0  7.0  27.0  7.0  1.0  4.0        ...          \n",
       "1        2  21.0   0.0   5.0  0.0  4.0   8.0  6.0  0.0  0.0        ...          \n",
       "2        3  11.0   5.0   0.0  0.0  4.0   4.0  5.0  1.0  2.0        ...          \n",
       "\n",
       "   193573  193579  193581  193583  193585  193587  193609  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "                     title                                       genres  \\\n",
       "0         Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "1           Jumanji (1995)                   Adventure|Children|Fantasy   \n",
       "2  Grumpier Old Men (1995)                               Comedy|Romance   \n",
       "\n",
       "              movie  \n",
       "0         toy story  \n",
       "1           jumanji  \n",
       "2  grumpier old men  \n",
       "\n",
       "[3 rows x 9728 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     1      2      3 ... 193585 193587 193609]\n",
      "[   0    1    2 ... 9721 9722 9723]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# creating a One Hot Encoder matrix\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data = reference[\"movieId\"].unique()\n",
    "values = array(data)\n",
    "print(values)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#taking input OHE to NN module\n",
    "\n",
    "movies_tensor = torch.from_numpy(onehot_encoded).float()\n",
    "movies_tensor= torch.tensor(movies_tensor)\n",
    "#movies_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 63482988.0\n",
      "20 22604410.0\n",
      "40 8410871.0\n",
      "60 5171159.0\n",
      "80 3722297.0\n",
      "100 2772058.0\n",
      "120 2110179.75\n",
      "140 1642771.875\n",
      "160 1306905.875\n",
      "180 1058600.125\n",
      "200 871652.125\n"
     ]
    }
   ],
   "source": [
    "# Creating a model to calulculate loss function and optimise using gradient descent\n",
    "\n",
    "import torch\n",
    "torch.nn.Linear\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "D_in,H, D_out = 9724, 300, 9724\n",
    "loss_array =[]\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = movies_tensor\n",
    "y = observed\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H,bias=0)\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(201):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    v_i = model(x)\n",
    "    v_j = v_i.t()\n",
    "    y_pred = torch.mm(v_i,v_j)\n",
    "    \n",
    "    \n",
    "    ind = np.diag_indices(y_pred.shape[0])\n",
    "    y_pred[ind[0], ind[1]] = torch.zeros(y_pred.shape[0])\n",
    "    y_pred\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 20 == 0:\n",
    "        print(t, loss.item())\n",
    "        loss_array.append(loss)\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss of cost function after 200 iterations is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of loss vs interations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Loss vs iteration plot\")\n",
    "plt.plot(loss_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending top 10 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a prediction function to give movie recommendations\n",
    "\n",
    "def prediction(moviename):\n",
    "    \n",
    "    #getting tensor for movie\n",
    "    moviename= moviename.lower()\n",
    "    idx = reference[reference[\"movie\"]== moviename].index[0]   \n",
    "    movie = movies_tensor[idx]\n",
    "    movie = movie.reshape(1,movie.shape[0])\n",
    "    \n",
    "    #storing weight vector from model\n",
    "    for name, param in model.named_parameters():\n",
    "        weight_vector = param\n",
    "    \n",
    "    # prediction for given movie\n",
    "    movie_i = model(movie)\n",
    "    pred = torch.mm(movie_i,weight_vector)\n",
    "    \n",
    "    # movie index value sorted from min to max for predicted score values\n",
    "    \n",
    "    pred_idx = (-np.asanyarray(pred[0].detach().numpy())).argsort()[:10]\n",
    "    \n",
    "    # Getting title of recommended movie from Reference Dataframe\n",
    "    recommendations = reference[\"title\"].iloc[pred_idx]\n",
    "    \n",
    "    return recommendations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a function to see top 10 movies recommendation for a movie in Xij matrix\n",
    "\n",
    "def observed_reco(moviename):\n",
    "    \n",
    "    # Getting Index of Movie from MovieId\n",
    "    idx = reference[reference[\"movie\"]== moviename].index[0]\n",
    "    \n",
    "    # Sorting top 10 movie indexes from Co-Occurence Matrix\n",
    "    obs_idx = (-np.asanyarray(rating_co_occ.iloc[idx])).argsort()[:10]\n",
    "    \n",
    "    # Getting movie title from top 10 movie indexes\n",
    "    recommendations = reference[\"title\"].iloc[obs_idx]\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 movie prediction for Apollo 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model Predictions:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "314                          Forrest Gump (1994)\n",
       "277             Shawshank Redemption, The (1994)\n",
       "257                          Pulp Fiction (1994)\n",
       "510             Silence of the Lambs, The (1991)\n",
       "123                             Apollo 13 (1995)\n",
       "97                             Braveheart (1995)\n",
       "418                         Jurassic Park (1993)\n",
       "398                         Fugitive, The (1993)\n",
       "461                      Schindler's List (1993)\n",
       "224    Star Wars: Episode IV - A New Hope (1977)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Actual Predictions:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "277             Shawshank Redemption, The (1994)\n",
       "314                          Forrest Gump (1994)\n",
       "257                          Pulp Fiction (1994)\n",
       "418                         Jurassic Park (1993)\n",
       "510             Silence of the Lambs, The (1991)\n",
       "398                         Fugitive, The (1993)\n",
       "97                             Braveheart (1995)\n",
       "461                      Schindler's List (1993)\n",
       "507            Terminator 2: Judgment Day (1991)\n",
       "224    Star Wars: Episode IV - A New Hope (1977)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Model Predictions:\",prediction(\"APOLLO 13\"),\"Actual Predictions:\", observed_reco(\"apollo 13\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 movie recommendations for Toy Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model Predictions:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "277                      Shawshank Redemption, The (1994)\n",
       "314                                   Forrest Gump (1994)\n",
       "257                                   Pulp Fiction (1994)\n",
       "510                      Silence of the Lambs, The (1991)\n",
       "224             Star Wars: Episode IV - A New Hope (1977)\n",
       "1938                                   Matrix, The (1999)\n",
       "897     Star Wars: Episode V - The Empire Strikes Back...\n",
       "899     Raiders of the Lost Ark (Indiana Jones and the...\n",
       "0                                        Toy Story (1995)\n",
       "418                                  Jurassic Park (1993)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Actual Predictions:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "277                      Shawshank Redemption, The (1994)\n",
       "314                                   Forrest Gump (1994)\n",
       "224             Star Wars: Episode IV - A New Hope (1977)\n",
       "257                                   Pulp Fiction (1994)\n",
       "510                      Silence of the Lambs, The (1991)\n",
       "897     Star Wars: Episode V - The Empire Strikes Back...\n",
       "1938                                   Matrix, The (1999)\n",
       "418                                  Jurassic Park (1993)\n",
       "899     Raiders of the Lost Ark (Indiana Jones and the...\n",
       "910     Star Wars: Episode VI - Return of the Jedi (1983)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Model Predictions:\",prediction(\"toy story\"),\"Actual Predictions:\", observed_reco(\"toy story\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 movie predictions for Home Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model Predictions:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "314                           Forrest Gump (1994)\n",
       "504                             Home Alone (1990)\n",
       "418                          Jurassic Park (1993)\n",
       "277              Shawshank Redemption, The (1994)\n",
       "506                                Aladdin (1992)\n",
       "322                         Lion King, The (1994)\n",
       "1938                           Matrix, The (1999)\n",
       "224     Star Wars: Episode IV - A New Hope (1977)\n",
       "0                                Toy Story (1995)\n",
       "510              Silence of the Lambs, The (1991)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Actual Predictions:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "314                   Forrest Gump (1994)\n",
       "418                  Jurassic Park (1993)\n",
       "277      Shawshank Redemption, The (1994)\n",
       "506                        Aladdin (1992)\n",
       "322                 Lion King, The (1994)\n",
       "507     Terminator 2: Judgment Day (1991)\n",
       "0                        Toy Story (1995)\n",
       "510      Silence of the Lambs, The (1991)\n",
       "1938                   Matrix, The (1999)\n",
       "257                   Pulp Fiction (1994)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Model Predictions:\",prediction(\"home alone\"),\"Actual Predictions:\", observed_reco(\"home alone\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Learning Rates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing the learning rate by 100 times to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 63482960.0\n",
      "20 8544730112.0\n",
      "40 797102976.0\n",
      "60 76067680.0\n",
      "80 17497732.0\n",
      "100 10002587.0\n",
      "120 7385810.0\n",
      "140 5871215.0\n",
      "160 4855597.0\n",
      "180 4121301.75\n",
      "200 3560509.25\n"
     ]
    }
   ],
   "source": [
    "# Changing learning rate to 1\n",
    "\n",
    "import torch\n",
    "torch.nn.Linear\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "D_in,H, D_out = 9724, 300, 9724\n",
    "loss_array =[]\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = movies_tensor\n",
    "y = observed\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H,bias=0)\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "learning_rate = 1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(201):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    v_i = model(x)\n",
    "    v_j = v_i.t()\n",
    "    y_pred = torch.mm(v_i,v_j)\n",
    "    \n",
    "    \n",
    "    ind = np.diag_indices(y_pred.shape[0])\n",
    "    y_pred[ind[0], ind[1]] = torch.zeros(y_pred.shape[0])\n",
    "    y_pred\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 20 == 0:\n",
    "        print(t, loss.item())\n",
    "        loss_array.append(loss)\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of loss vs interations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Loss vs iteration plot\")\n",
    "plt.plot(loss_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The predictions for Apollo 13 show that these are similar to the actual predictions but still the recommedations are a little different from the actual predictions and from what we got when the learning rate was 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4607                             Kill Bill: Vol. 1 (2003)\n",
       "827                                 Reservoir Dogs (1992)\n",
       "123                                      Apollo 13 (1995)\n",
       "224             Star Wars: Episode IV - A New Hope (1977)\n",
       "314                                   Forrest Gump (1994)\n",
       "3814                                    Spider-Man (2002)\n",
       "3633    Lord of the Rings: The Fellowship of the Ring,...\n",
       "4131        Lord of the Rings: The Two Towers, The (2002)\n",
       "2729                               Blazing Saddles (1974)\n",
       "1260                             Starship Troopers (1997)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"apollo 13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowering the learning rate by 100 times to 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 63482976.0\n",
      "20 63456452.0\n",
      "40 63351876.0\n",
      "60 63136012.0\n",
      "80 62801520.0\n",
      "100 62358824.0\n",
      "120 61824716.0\n",
      "140 61216272.0\n",
      "160 60548940.0\n",
      "180 59835288.0\n",
      "200 59085028.0\n"
     ]
    }
   ],
   "source": [
    "# Lowering the learning rate by 100 times to 0.0001\n",
    "\n",
    "import torch\n",
    "torch.nn.Linear\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "D_in,H, D_out = 9724, 300, 9724\n",
    "loss_array =[]\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = movies_tensor\n",
    "y = observed\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H,bias=0)\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(201):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    v_i = model(x)\n",
    "    v_j = v_i.t()\n",
    "    y_pred = torch.mm(v_i,v_j)\n",
    "    \n",
    "    \n",
    "    ind = np.diag_indices(y_pred.shape[0])\n",
    "    y_pred[ind[0], ind[1]] = torch.zeros(y_pred.shape[0])\n",
    "    y_pred\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 20 == 0:\n",
    "        print(t, loss.item())\n",
    "        loss_array.append(loss)\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of loss vs interations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Loss vs iteration plot\")\n",
    "plt.plot(loss_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The predictions for Apollo 13 will show that these are much different than the actual predictions and also from the one we have recommended when the learning rate is 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4607                             Kill Bill: Vol. 1 (2003)\n",
       "827                                 Reservoir Dogs (1992)\n",
       "123                                      Apollo 13 (1995)\n",
       "224             Star Wars: Episode IV - A New Hope (1977)\n",
       "314                                   Forrest Gump (1994)\n",
       "3814                                    Spider-Man (2002)\n",
       "3633    Lord of the Rings: The Fellowship of the Ring,...\n",
       "4131        Lord of the Rings: The Two Towers, The (2002)\n",
       "2729                               Blazing Saddles (1974)\n",
       "1260                             Starship Troopers (1997)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"apollo 13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate scales the magnitude of our weights in order to minimize the network's loss function. If learning rate is set to a high value it would keep bouncing as it nears the optimal point and my not reach the optimal point and thus give us incorrect recommendations. Whereas, if learning rate is too small, then training will progress very slowly as we are making very tiny updates to the weight and there is a chance to get stuck in local minima and our gradient descent function will give constant loss with increase in iterations, resulting in high cost and incorrect recommendations."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
